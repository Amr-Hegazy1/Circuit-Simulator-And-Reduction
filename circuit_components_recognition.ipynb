{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7Y-FKzvULCn",
        "outputId": "4b8921dd-e377-4fe9-f558-342d1a5cc58f"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "path = '.\\\\handrawn_circuits2\\\\'\n",
        "\n",
        "new_path = '.\\\\handrawn_circuits2\\\\all\\\\images\\\\'\n",
        "\n",
        "# move all images to a single folder\n",
        "\n",
        "folders = os.listdir(path)\n",
        "\n",
        "for folder in folders:\n",
        "    if folder == all or os.path.isfile(path + folder):\n",
        "        continue\n",
        "    \n",
        "    files = os.listdir(path + folder + \"\\\\images\\\\\")\n",
        "    for file in files:\n",
        "        os.rename(path + folder + \"\\\\images\\\\\" + file, new_path + file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "path = '.\\\\handrawn_circuits2\\\\'\n",
        "\n",
        "new_path = '.\\\\handrawn_circuits2\\\\all\\\\annotations\\\\'\n",
        "\n",
        "# move all annotations to a single folder\n",
        "\n",
        "for folder in folders:\n",
        "    if folder == all or os.path.isfile(path + folder):\n",
        "        continue\n",
        "    \n",
        "    files = os.listdir(path + folder + \"\\\\annotations\\\\\")\n",
        "    for file in files:\n",
        "        os.rename(path + folder + \"\\\\annotations\\\\\" + file, new_path + file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python xml_to_txt.py -i handrawn_circuits2/all/annotations -o handrawn_circuits2/all/labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "old_classes = json.load(open(\"./handrawn_circuits2/classes.json\", \"r\"))\n",
        "\n",
        "# old_classes2 = ['AC_Source', 'BJT', 'Battery', 'Capacitor', 'Current_Source', 'DC_Source', 'Diode', 'Ground', 'Inductor', 'MOSFET', 'Resistor', 'Voltage_Source']\n",
        "\n",
        "# new_classes = {}\n",
        "\n",
        "# for i in range(len(old_classes2)):\n",
        "#     new_classes[old_classes2[i]] = i\n",
        "    \n",
        "# for old_class in old_classes:\n",
        "#     if old_classes == \"voltage.ac\" or old_classes == \"voltage.dc\" or :\n",
        "#         continue\n",
        "#     new_classes[old_class] = old_classes[old_class]\n",
        "\n",
        "# display list of classes\n",
        "\n",
        "len(old_classes.keys())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Requirement already satisfied: torch in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (2.0.1+cu117)\n",
            "Requirement already satisfied: torchvision in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (0.15.2+cu117)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (2.0.2+cu117)\n",
            "Requirement already satisfied: ultralytics in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (8.0.139)\n",
            "Requirement already satisfied: filelock in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from torch) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from torch) (3.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from torchvision) (1.24.1)\n",
            "Requirement already satisfied: requests in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from torchvision) (2.28.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from torchvision) (9.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from ultralytics) (3.7.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from ultralytics) (4.8.0.74)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from ultralytics) (1.11.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from requests->torchvision) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\emerg\\desktop\\python\\circuit-simulator-and-reduction\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall ultralytics torch torchvision torchaudio\n",
        "!pip install torch torchvision torchaudio ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRwLrxG92q5r",
        "outputId": "37d72de6-04c0-4377-9c65-3b4436e05b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmbY9wtQTCEM",
        "outputId": "8b12111b-1794-440e-a451-116a9c3cd32a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# !cp -r /content/drive/MyDrive/datasets/handrawn_circuits /content\n",
        "# %unzip /handrawn_circuits.zip -d /handrawn_circuits\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdLrMx-S2s7h",
        "outputId": "3682be21-b228-4a06-81ea-e049bfcf9c1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.0.175 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.141  Python-3.10.11 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\recognition of direction arrows for autonomus car.v4i.yolov8\\data.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\runs\\detect\\train10\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011628 parameters, 3011612 gradients\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir c:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\runs\\detect\\train10', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\recognition of direction arrows for autonomus car.v4i.yolov8\\train\\labels... 7258 images, 5362 backgrounds, 0 corrupt: 100%|██████████| 7258/7258 [00:13<00:00, 518.90it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\recognition of direction arrows for autonomus car.v4i.yolov8\\train\\labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\recognition of direction arrows for autonomus car.v4i.yolov8\\valid\\labels... 708 images, 541 backgrounds, 0 corrupt: 100%|██████████| 708/708 [00:01<00:00, 435.14it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\recognition of direction arrows for autonomus car.v4i.yolov8\\valid\\labels.cache\n",
            "Plotting labels to c:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\runs\\detect\\train10\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mc:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\runs\\detect\\train10\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100      2.13G     0.8828      4.333      1.324          8        640: 100%|██████████| 454/454 [02:12<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:09<00:00,  2.44it/s]\n",
            "                   all        708        167   0.000281      0.218   0.000448   0.000133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100      2.15G     0.8501      2.793      1.237         11        640: 100%|██████████| 454/454 [02:04<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:08<00:00,  2.56it/s]\n",
            "                   all        708        167      0.124     0.0476     0.0553     0.0252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100      2.15G     0.9897      1.953      1.324          6        640: 100%|██████████| 454/454 [02:02<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:09<00:00,  2.43it/s]\n",
            "                   all        708        167      0.123      0.272      0.116     0.0588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100      2.14G      1.063      1.684      1.376          4        640: 100%|██████████| 454/454 [02:03<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:08<00:00,  2.61it/s]\n",
            "                   all        708        167     0.0717     0.0666     0.0473     0.0261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100      2.15G     0.9699       1.45      1.297          6        640: 100%|██████████| 454/454 [02:03<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:09<00:00,  2.53it/s]\n",
            "                   all        708        167      0.187      0.443      0.188      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100      2.14G      0.905      1.218      1.245          7        640: 100%|██████████| 454/454 [02:02<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:08<00:00,  2.65it/s]\n",
            "                   all        708        167      0.344      0.159      0.242      0.145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100      2.14G     0.8274      1.086      1.196          6        640: 100%|██████████| 454/454 [02:03<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:09<00:00,  2.49it/s]\n",
            "                   all        708        167     0.0678      0.176     0.0651     0.0259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/100      2.14G     0.8132      1.054      1.193          5        640: 100%|██████████| 454/454 [02:03<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:09<00:00,  2.39it/s]\n",
            "                   all        708        167      0.382      0.315      0.232      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/100      2.15G     0.7574     0.9797      1.148          8        640: 100%|██████████| 454/454 [02:03<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:09<00:00,  2.47it/s]\n",
            "                   all        708        167      0.341      0.595      0.411      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/100      2.13G     0.7212     0.9211      1.136          6        640:  20%|██        | 91/454 [00:25<01:39,  3.65it/s]"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.train(data='C:\\\\Users\\\\emerg\\\\Desktop\\\\Python\\\\Circuit-Simulator-And-Reduction\\\\recognition of direction arrows for autonomus car.v4i.yolov8\\\\data.yaml', epochs=100, imgsz=640)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GSOAosr3dec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.141  Python-3.10.11 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
            "Model summary (fused): 168 layers, 3014423 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\Electronic circuits.v1i.yolov8\\valid\\labels.cache... 230 images, 0 backgrounds, 0 corrupt: 100%|██████████| 230/230 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  1.99it/s]\n",
            "                   all        230       9807      0.899      0.905      0.943      0.742\n",
            "                   and        230         15      0.924          1      0.995      0.836\n",
            "               antenna        230          2      0.999          1      0.995      0.648\n",
            "   capacitor-polarized        230         63      0.952      0.937      0.956      0.728\n",
            " capacitor-unpolarized        230        292      0.951      0.914      0.946      0.644\n",
            "             crossover        230        267      0.884      0.654      0.805      0.383\n",
            "                  diac        230          3          1      0.841      0.995       0.81\n",
            "                 diode        230        252      0.948      0.972      0.985      0.734\n",
            "  diode-light_emitting        230         92      0.889      0.989       0.98       0.76\n",
            "                  fuse        230          5      0.902        0.8      0.798      0.718\n",
            "                   gnd        230        150      0.984       0.98      0.986      0.706\n",
            "              inductor        230         50      0.958       0.96      0.964      0.764\n",
            "    integrated_circuit        230         29       0.93          1      0.995       0.93\n",
            "integrated_cricuit-ne555        230         31          1       0.99      0.995      0.933\n",
            "              junction        230       3714      0.913      0.749      0.851      0.378\n",
            "                  lamp        230         21      0.909      0.905      0.973      0.792\n",
            "            microphone        230          1       0.33          1      0.995      0.895\n",
            "                 motor        230          4      0.917          1      0.995      0.821\n",
            "                  nand        230         13      0.948          1      0.995      0.959\n",
            "                   nor        230         10      0.935          1      0.995      0.955\n",
            "                   not        230         26      0.966          1      0.995      0.849\n",
            " operational_amplifier        230         11       0.94          1      0.995      0.927\n",
            "           optocoupler        230         10      0.918        0.9      0.978      0.732\n",
            "                    or        230         16      0.816          1      0.995      0.933\n",
            "         probe-current        230          2      0.762          1      0.995      0.947\n",
            "                 relay        230          4      0.645       0.75      0.888      0.719\n",
            "              resistor        230        672      0.942      0.946      0.972      0.672\n",
            "   resistor-adjustable        230         36      0.704       0.66      0.709      0.422\n",
            "        resistor-photo        230          6      0.809      0.712      0.815      0.682\n",
            "       schmitt_trigger        230          4      0.844          1      0.995      0.921\n",
            "                socket        230          8      0.909          1      0.995      0.868\n",
            "               speaker        230         36      0.939      0.944      0.986      0.808\n",
            "                switch        230         67      0.849      0.806      0.925      0.601\n",
            "              terminal        230        543      0.879      0.757      0.832      0.448\n",
            "                  text        230       2890      0.914       0.93      0.966      0.684\n",
            "             thyristor        230         84      0.954      0.976      0.985      0.728\n",
            "           transformer        230         25      0.945          1      0.995      0.877\n",
            "            transistor        230        173      0.903      0.965      0.983       0.75\n",
            "                 triac        230          8          1      0.904      0.995      0.606\n",
            "              varistor        230         38      0.873          1      0.965      0.762\n",
            "            voltage-dc        230         70       0.94      0.943      0.969      0.802\n",
            "         voltage-dc_ac        230         19      0.937      0.781      0.901      0.811\n",
            "  voltage-dc_regulator        230          5          1       0.54      0.656      0.474\n",
            "                   vss        230         34          1      0.612      0.824      0.368\n",
            "                   xor        230          6      0.878          1      0.995      0.882\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mc:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\runs\\detect\\val8\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([    0.83586,     0.64796,       0.728,     0.64371,     0.38277,      0.8096,     0.73428,     0.75983,     0.71792,     0.70643,     0.76369,     0.93015,     0.93304,     0.37764,     0.79219,      0.8955,     0.82097,     0.95855,     0.95481,     0.84905,     0.92741,     0.73153,     0.93319,      0.9467,\n",
              "           0.71854,     0.67227,     0.42234,     0.68212,     0.92098,     0.86803,     0.80806,     0.60055,     0.44772,     0.68433,     0.72751,     0.87677,     0.75042,      0.7424,      0.6064,     0.76248,     0.80166,     0.81062,     0.47405,      0.3675,     0.88245])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = YOLO('C:\\\\Users\\\\emerg\\\\Desktop\\\\Python\\\\Circuit-Simulator-And-Reduction\\\\runs\\\\detect\\\\train10\\\\weights\\\\best.pt')  # load a custom model\n",
        "\n",
        "# Validate the model\n",
        "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
        "metrics.box.map    # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps   # a list contains map50-95 of each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1LeZM2mEraH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 c:\\Users\\emerg\\Desktop\\Python\\Circuit-Simulator-And-Reduction\\circuit4.png: 320x640 1 crossover, 8 junctions, 4 resistors, 1 switch, 10 texts, 2 voltage-dcs, 30.9ms\n",
            "Speed: 4.3ms preprocess, 30.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('C:\\\\Users\\\\emerg\\\\Desktop\\\\Python\\\\Circuit-Simulator-And-Reduction\\\\runs\\\\detect\\\\train10\\\\weights\\\\best.pt')  # pretrained YOLOv8n model\n",
        "\n",
        "# Run batched inference on a list of images\n",
        "result = model('current_source.png')  # return a list of Results objects\n",
        "\n",
        "res_plotted = result[0].plot()\n",
        "\n",
        "# display image\n",
        "\n",
        "img = Image.fromarray(res_plotted, 'RGB')\n",
        "img.save('my.png')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ie66dR423MgU"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# files.download(\"/content/runs/detect/train/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St56T35mByCH"
      },
      "source": [
        "@software{yolov8_ultralytics,\n",
        "  author       = {Glenn Jocher and Ayush Chaurasia and Jing Qiu},\n",
        "  title        = {Ultralytics YOLOv8},\n",
        "  version      = {8.0.0},\n",
        "  year         = {2023},\n",
        "  url          = {https://github.com/ultralytics/ultralytics},\n",
        "  orcid        = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},\n",
        "  license      = {AGPL-3.0}\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
